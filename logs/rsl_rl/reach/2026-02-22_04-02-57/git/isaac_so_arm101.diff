--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   src/isaac_so_arm101/tasks/reach/reach_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/rsl_rl/reach/2026-02-22_04-02-57/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/src/isaac_so_arm101/tasks/reach/reach_env_cfg.py b/src/isaac_so_arm101/tasks/reach/reach_env_cfg.py
index d5e5d31..4872287 100644
--- a/src/isaac_so_arm101/tasks/reach/reach_env_cfg.py
+++ b/src/isaac_so_arm101/tasks/reach/reach_env_cfg.py
@@ -157,7 +157,9 @@ class RewardsCfg:
     )
 
     # action penalty
-    action_rate = RewTerm(func=mdp.action_rate_l2, weight=-0.005)  # -0.0001 → -0.005：强力抑制目标附近极限环振荡
+    # action_rate=-0.005 配合 entropy_coef=0.01：σ_eq ≈ 3.5×0.01/√0.005 ≈ 0.50（探索期甜点）
+    # curriculum 在 ~500 RL iter 后升至 -0.01 → σ_eq≈0.35（稳定期）
+    action_rate = RewTerm(func=mdp.action_rate_l2, weight=-0.005)
     joint_vel = RewTerm(
         func=mdp.joint_vel_l2,
         weight=-0.0001,
@@ -188,14 +190,23 @@ class TerminationsCfg:
 class CurriculumCfg:
     """Curriculum terms for the MDP."""
 
+    # num_steps 单位是 env steps（非 RL iters）
+    # 1 RL iter = 4096 envs × 32 steps = 131,072 env steps
+    # 65_000_000 env steps ≈ 500 RL iters（在 max_iterations=3000 的 1/6 处触发）
+    #
+    # 两阶段训练策略：
+    #   阶段1 (iter 0-500):   action_rate=-0.005 → σ_eq≈0.50，充足探索，策略学习主动精细接近
+    #   阶段2 (iter 500-3000): action_rate=-0.01  → σ_eq≈0.35，抑制振荡，策略精细化
     action_rate = CurrTerm(
-        func=mdp.modify_reward_weight, params={"term_name": "action_rate", "weight": -0.01, "num_steps": 2000}
-        # -0.005 → -0.01：初始已强化，curriculum 继续加压；num_steps 2000 < max_iterations 确保生效
+        func=mdp.modify_reward_weight,
+        params={"term_name": "action_rate", "weight": -0.01, "num_steps": 65_000_000},
     )
 
+    # joint_vel 同理：阶段1 保持 -0.0001，阶段2 升至 -0.001（10×），配合 action_rate 共同抑制振荡
+    # 注意：final weight=-0.001（而非原来的 -0.005，-0.005 = 50× 初始值，过于激进）
     joint_vel = CurrTerm(
-        func=mdp.modify_reward_weight, params={"term_name": "joint_vel", "weight": -0.005, "num_steps": 2000}
-        # -0.0001 → -0.005：随训练进行逐步惩罚关节速度，稳定收敛后的停留姿态
+        func=mdp.modify_reward_weight,
+        params={"term_name": "joint_vel", "weight": -0.001, "num_steps": 65_000_000},
     )
 
 